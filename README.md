# âœ¨ L02 â€“ NLP Preprocessing Techniques: From Raw Text to Real Insight

**Course:** ITAI 2373 â€“ Natural Language Processing  
**Student:** Sharise Griggs  
**Assignment:** Lab 02 â€“ Text Cleaning & Preprocessing  
**Instructor:** Patricia McManus  
**Score:** âœ… 98 / 100

---

## ğŸ“– Project Overview

This lab was my official dive into the world of **text preprocessing** â€” the behind-the-scenes magic that transforms messy, human language into clean, usable data for machines to understand.

I learned quickly that this isnâ€™t just a â€œsetup stepâ€ in NLP... it's where **meaning is made or destroyed**. Every decision here â€” from removing stopwords to choosing lemmatization over stemming â€” can make or break your results.

---

## ğŸ’¡ What I Explored

| ğŸ”§ Task                        | ğŸ’¬ My Insight |
|-------------------------------|----------------|
| Tokenization                  | Split text into usable units using NLTK & spaCy |
| Stopword Filtering            | Realized that removing â€œnotâ€ can destroy sentiment |
| Stemming vs. Lemmatization    | Saw how aggressive stemming distorts meaning |
| spaCy vs. NLTK                | spaCy handled slang, emojis, and hashtags better |
| Error Handling (NLTK `punkt`) | Learned how to debug tokenizer failures in Colab |
| Custom Cleaning Functions     | Built toggleable pipelines for "light" or "heavy" preprocessing |

---

## ğŸŒŸ Reflection Snippet

> â€œIf you mess up here, your whole model might fall apart â€” no matter how fancy it is.â€

This lab made it clear that preprocessing isn't boring boilerplate â€” it's where your model learns what *not* to forget. I now approach cleaning with respect and flexibility depending on context (e.g., preserving emojis in mental health journaling apps).

---

## ğŸ§  Tools & Technologies Used

- ğŸ Python 3.x  
- ğŸ“š NLTK (Natural Language Toolkit)  
- ğŸ’¬ spaCy  
- ğŸ§ª Google Colab (Jupyter environment)

---

## ğŸ§ª How to Run This Notebook

### ğŸ”§ Installation Requirements

```bash
pip install nltk
pip install spacy
python -m nltk.downloader all
python -m spacy download en_core_web_sm
